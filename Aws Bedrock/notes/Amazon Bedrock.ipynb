{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f6e321cb",
   "metadata": {},
   "source": [
    "# Amazon Bedrock: A Serverless Foundation Model Service\n",
    "\n",
    "## Table of Contents\n",
    "1. [Introduction](#introduction)\n",
    "2. [Key Features](#key-features)\n",
    "3. [How It Works](#how-it-works)\n",
    "4. [Supported Foundation Models](#supported-foundation-models)\n",
    "5. [Next Steps](#next-steps)\n",
    "\n",
    "## Introduction\n",
    "Amazon Bedrock is a fully managed serverless service from AWS that provides API access to various foundation models from Amazon and third-party providers.\n",
    "\n",
    "## Key Features\n",
    "- <span style=\"color:blue\">#serverless</span> Fully managed and serverless\n",
    "- <span style=\"color:blue\">#api</span> Unified API for multiple foundation models\n",
    "- <span style=\"color:blue\">#payperyuse</span> Pay-per-use pricing model\n",
    "- <span style=\"color:blue\">#thirdparty</span> Access to third-party foundation models\n",
    "\n",
    "## How It Works\n",
    "1. Users access Bedrock via AWS Console, CLI, or SDK\n",
    "2. API requests include prompt and configuration parameters\n",
    "3. Bedrock routes requests to appropriate hosted foundation model\n",
    "4. Foundation model processes request and returns response\n",
    "\n",
    "## Supported Foundation Models\n",
    "- <span style=\"color:blue\">#amazon</span> Amazon Titan: General purpose model\n",
    "- <span style=\"color:blue\">#ai21labs</span> AI21 Labs Jurassic-2: Multilingual text generation\n",
    "- <span style=\"color:blue\">#anthropic</span> Anthropic Claude: Question answering and workflow automation\n",
    "- <span style=\"color:blue\">#stability</span> Stability AI Stable Diffusion: Image generation\n",
    "\n",
    "## Next Steps\n",
    "- Explore model selection criteria\n",
    "- Learn about configuration parameters\n",
    "- Dive deeper into specific use cases for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "321bae6d",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Console Walkthrough\n",
    "\n",
    "## Table of Contents\n",
    "1. [Accessing Amazon Bedrock](#accessing-amazon-bedrock)\n",
    "2. [Requesting Model Access](#requesting-model-access)\n",
    "3. [Console Overview](#console-overview)\n",
    "4. [Foundation Models](#foundation-models)\n",
    "5. [Understanding Max Tokens](#understanding-max-tokens)\n",
    "\n",
    "## Accessing Amazon Bedrock\n",
    "- <span style=\"color:blue\">#console</span> Access Amazon Bedrock through AWS console\n",
    "- <span style=\"color:blue\">#region</span> Service available in limited regions (e.g., US East North Virginia)\n",
    "\n",
    "## Requesting Model Access\n",
    "- <span style=\"color:blue\">#modelaccess</span> Navigate to \"Model Access\" in the sidebar\n",
    "- <span style=\"color:blue\">#requestaccess</span> Select desired models and submit access request\n",
    "- <span style=\"color:blue\">#waittime</span> Access granted within minutes to hours\n",
    "\n",
    "## Console Overview\n",
    "- <span style=\"color:blue\">#overview</span> Provides details on foundation models\n",
    "- <span style=\"color:blue\">#playground</span> Test models before enterprise implementation\n",
    "- <span style=\"color:blue\">#handsonlabs</span> Available for practical learning\n",
    "\n",
    "## Foundation Models\n",
    "- <span style=\"color:blue\">#providers</span> Models from various providers (Anthropic, Cohere, AI21 Labs, etc.)\n",
    "- <span style=\"color:blue\">#modalities</span> Three main modalities: text, embeddings, and image\n",
    "- <span style=\"color:blue\">#versions</span> Different versions available for some models\n",
    "\n",
    "## Understanding Max Tokens\n",
    "- <span style=\"color:blue\">#maxtokens</span> Limit on combined input and output tokens\n",
    "- <span style=\"color:blue\">#tokencount</span> Approximately 4 characters or 0.75 words per token\n",
    "- <span style=\"color:blue\">#examples</span>\n",
    "  - Anthropic Claude: 100K tokens (≈75,000 words)\n",
    "  - Cohere: 4000 tokens (≈3000 words)\n",
    "  - Stability Diffusion: 77 tokens (≈58 words for input prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df24246e",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Advanced Features\n",
    "\n",
    "## Table of Contents\n",
    "1. [Custom Models](#custom-models)\n",
    "2. [Model Providers](#model-providers)\n",
    "3. [Playground](#playground)\n",
    "4. [Provisioned Throughput](#provisioned-throughput)\n",
    "5. [Examples](#examples)\n",
    "\n",
    "## Custom Models\n",
    "- <span style=\"color:blue\">#finetune</span> Fine-tune base models for specific domains\n",
    "- <span style=\"color:blue\">#process</span> Select source model, provide labeled data, configure hyperparameters\n",
    "- <span style=\"color:blue\">#availability</span> Currently limited to Titan Express and Titan Lite models\n",
    "- <span style=\"color:blue\">#inputformat</span> JSON format for input and expected output\n",
    "\n",
    "## Model Providers\n",
    "- <span style=\"color:blue\">#details</span> Provides information on each provider and their models\n",
    "- <span style=\"color:blue\">#usecases</span> Lists popular use cases for each model\n",
    "- <span style=\"color:blue\">#examples</span> Offers example prompts and responses\n",
    "\n",
    "## Playground\n",
    "- <span style=\"color:blue\">#testing</span> Environment to test models and adjust inference parameters\n",
    "- <span style=\"color:blue\">#models</span> Includes text, chat, and image generation models\n",
    "- <span style=\"color:blue\">#configuration</span> Allows adjustment of inference settings like temperature\n",
    "\n",
    "## Provisioned Throughput\n",
    "- <span style=\"color:blue\">#customdeployment</span> Required for deploying custom models\n",
    "- <span style=\"color:blue\">#cost</span> Significantly more expensive than serverless base model usage\n",
    "- <span style=\"color:blue\">#pricing</span> Based on model units and commitment period\n",
    "\n",
    "## Examples\n",
    "- <span style=\"color:blue\">#usecase</span> AWS-provided examples for various tasks\n",
    "- <span style=\"color:blue\">#categories</span> Includes content generation, entity extraction, image creation, etc.\n",
    "- <span style=\"color:blue\">#exploration</span> Useful for understanding common applications of the models\n",
    "\n",
    "## Key Points\n",
    "- <span style=\"color:blue\">#costaware</span> Be mindful of costs, especially with provisioned throughput\n",
    "- <span style=\"color:blue\">#exploration</span> Playground and examples are useful for testing and learning\n",
    "- <span style=\"color:blue\">#modelselection</span> Consider specific use cases when choosing models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1c833f",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Architecture (Part 1)\n",
    "\n",
    "## Table of Contents\n",
    "1. [AWS Service Deployment Modes](#aws-service-deployment-modes)\n",
    "2. [Bedrock Service Architecture](#bedrock-service-architecture)\n",
    "3. [API Request Methods](#api-request-methods)\n",
    "4. [Request Flow](#request-flow)\n",
    "5. [Networking Options](#networking-options)\n",
    "\n",
    "## AWS Service Deployment Modes\n",
    "- <span style=\"color:blue\">#customerVPC</span> Services deployed in customer's VPC (e.g., EC2, RDS)\n",
    "- <span style=\"color:blue\">#awsManaged</span> Services deployed in AWS-managed accounts (e.g., Lambda, API Gateway)\n",
    "\n",
    "## Bedrock Service Architecture\n",
    "- <span style=\"color:blue\">#serviceAccount</span> Bedrock deployed in AWS-managed Bedrock Service Account\n",
    "- <span style=\"color:blue\">#modelProvider</span> Foundation models hosted in AWS-owned Model Provider Escrow Account\n",
    "- <span style=\"color:blue\">#storage</span> Base models stored in S3 buckets within AWS-managed account\n",
    "\n",
    "## API Request Methods\n",
    "1. <span style=\"color:blue\">#browser</span> Through web browser\n",
    "2. <span style=\"color:blue\">#awsCLI</span> Using AWS CLI\n",
    "3. <span style=\"color:blue\">#apiRequest</span> Via AWS services (e.g., Lambda)\n",
    "\n",
    "## Request Flow\n",
    "1. <span style=\"color:blue\">#requestInitiation</span> User initiates request\n",
    "2. <span style=\"color:blue\">#runtimeInference</span> Bedrock service determines appropriate foundation model\n",
    "3. <span style=\"color:blue\">#modelExecution</span> Request sent to specific model provider account\n",
    "4. <span style=\"color:blue\">#responseReturn</span> Response returned to user\n",
    "\n",
    "## Networking Options\n",
    "- <span style=\"color:blue\">#internet</span> API requests over the internet\n",
    "- <span style=\"color:blue\">#vpcEndpoint</span> Private connectivity via VPC interface endpoints\n",
    "\n",
    "## Additional Features\n",
    "- <span style=\"color:blue\">#promptHistory</span> Stores queries made through console for experimentation\n",
    "\n",
    "## VPC Endpoint Setup\n",
    "1. Navigate to VPC dashboard\n",
    "2. Select \"Endpoints\"\n",
    "3. Create new endpoint\n",
    "4. Search for \"bedrock\"\n",
    "5. Select the interface endpoint for Bedrock service"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a163d768",
   "metadata": {},
   "source": [
    "# Foundation Model Inference Parameters\n",
    "\n",
    "## Table of Contents\n",
    "1. [Classification of Inference Parameters](#classification-of-inference-parameters)\n",
    "2. [Randomness and Diversity](#randomness-and-diversity)\n",
    "3. [Temperature](#temperature)\n",
    "4. [Top K](#top-k)\n",
    "5. [Top P](#top-p)\n",
    "6. [Practical Examples](#practical-examples)\n",
    "\n",
    "## Classification of Inference Parameters\n",
    "<span style=\"color:blue\">#inferenceParameters</span>\n",
    "- Randomness and Diversity: Temperature, Top K, Top P\n",
    "- Response Length: Response length, Length penalty, Stop sequence\n",
    "- Repetition: Repetition penalty\n",
    "\n",
    "## Randomness and Diversity\n",
    "<span style=\"color:blue\">#randomnessAndDiversity</span>\n",
    "- Most important parameter category\n",
    "- Influences the variety and unpredictability of responses\n",
    "- Example prompt: \"I hear the hoofbeats of...\"\n",
    "- Model generates multiple possible word completions with associated probabilities\n",
    "\n",
    "## Temperature\n",
    "<span style=\"color:blue\">#temperature</span>\n",
    "- Range: Typically 0 to 1 or 0 to 5, depending on the model\n",
    "- Function:\n",
    "  - Low values (close to 0): Favor high-probability words, less random\n",
    "  - High values: Favor more diverse, potentially less probable words\n",
    "- Example:\n",
    "  - Low temperature might consistently output \"horse\"\n",
    "  - High temperature might output less common words like \"change in distance\"\n",
    "\n",
    "## Top K\n",
    "<span style=\"color:blue\">#topK</span>\n",
    "- Definition: Limits selection to top K most probable words\n",
    "- Range: Varies by model (e.g., 1 to 500 for Cohere)\n",
    "- Function:\n",
    "  - Filters out less probable words before applying temperature\n",
    "  - Example: If K=3, only considers top 3 most probable words\n",
    "- Interaction with temperature:\n",
    "  - Low temperature: Selects highest probability word from top K\n",
    "  - High temperature: May select lower probability words from top K\n",
    "\n",
    "## Top P (Nucleus Sampling)\n",
    "<span style=\"color:blue\">#topP</span>\n",
    "- Definition: Caps choices based on cumulative probability\n",
    "- Range: Typically 0.01 to 0.99\n",
    "- Function:\n",
    "  - Selects words until cumulative probability exceeds threshold\n",
    "  - Example: If P=0.5, selects words until their combined probability > 0.5\n",
    "- Provides dynamic cutoff compared to fixed Top K\n",
    "\n",
    "## Practical Examples\n",
    "<span style=\"color:blue\">#practicalExamples</span>\n",
    "- Demonstrated using Amazon Bedrock console\n",
    "- Model used: Cohere\n",
    "- Tests performed:\n",
    "  1. Low temperature (0): Consistently output \"horse\" or \"horses\"\n",
    "  2. High temperature (5): Expected diverse outputs, but results varied\n",
    "  3. Adjusting Top K: Set to 45, limiting word choices\n",
    "  4. Modifying Top P: Set to 0.64, affecting probability cutoff\n",
    "- Observations: Changing parameter combinations led to varied responses\n",
    "\n",
    "## Key Points\n",
    "<span style=\"color:blue\">#keyPoints</span>\n",
    "- Parameter interaction: Temperature, Top K, and Top P work together to affect final output\n",
    "- Model variation: Parameter ranges and effects can differ between foundation models\n",
    "- Experimentation: Adjusting parameters can lead to diverse responses for the same prompt\n",
    "- Practical application: Understanding these parameters helps in fine-tuning model outputs for specific use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa4abe1",
   "metadata": {},
   "source": [
    "# Foundation Model Inference Parameters: Length and Repetition\n",
    "\n",
    "## Table of Contents\n",
    "1. [Length Parameters](#length-parameters)\n",
    "2. [Repetition Parameters](#repetition-parameters)\n",
    "3. [Practical Examples](#practical-examples)\n",
    "\n",
    "## Length Parameters\n",
    "<span style=\"color:blue\">#lengthParameters</span>\n",
    "\n",
    "### Max Length\n",
    "- <span style=\"color:blue\">#maxLength</span>\n",
    "- Definition: Controls the length of the generated response\n",
    "- Range: Typically 1 to 4,096 tokens (varies by model)\n",
    "- Importance:\n",
    "  - Helps control the cost of API usage\n",
    "  - 1 token ≈ 4 characters ≈ 0.75 words\n",
    "- Example: 4,096 tokens ≈ 3,000 words\n",
    "- Pricing impact:\n",
    "  - Pricing often based on per 1,000 tokens\n",
    "  - E.g., AI21 Labs: $0.0125 per 1,000 input tokens\n",
    "\n",
    "### Stop Sequence\n",
    "- <span style=\"color:blue\">#stopSequence</span>\n",
    "- Function: Stops token generation when specified keyword is encountered\n",
    "- Usage:\n",
    "  - Can define up to 4 sequences\n",
    "  - Generated text does not include the stop sequence\n",
    "- Application: Useful for controlling response format or length\n",
    "\n",
    "## Repetition Parameters\n",
    "<span style=\"color:blue\">#repetitionParameters</span>\n",
    "\n",
    "### Presence Penalty\n",
    "- <span style=\"color:blue\">#presencePenalty</span>\n",
    "- Range: 0 to 5\n",
    "- Function: Higher values reduce probability of repeating tokens from prompt or completion\n",
    "\n",
    "### Count Penalty\n",
    "- <span style=\"color:blue\">#countPenalty</span>\n",
    "- Range: 0 to 1\n",
    "- Function: Higher values lower probability of word repetition, proportional to appearances\n",
    "\n",
    "### Frequency Penalty\n",
    "- <span style=\"color:blue\">#frequencyPenalty</span>\n",
    "- Range: 0 to 500\n",
    "- Function: Higher values reduce probability of repeating tokens, normalized to text length\n",
    "\n",
    "### Penalize Special Token\n",
    "- <span style=\"color:blue\">#penalizeSpecialToken</span>\n",
    "- Function: Reduces probability of repeating special characters (e.g., whitespaces, punctuations)\n",
    "\n",
    "## Practical Examples\n",
    "<span style=\"color:blue\">#practicalExamples</span>\n",
    "\n",
    "### Length Parameter Demo\n",
    "- Used AI21 Labs model in Amazon Bedrock console\n",
    "- Prompt: \"Write an essay on horse\"\n",
    "- Test 1:\n",
    "  - Max length: 200 tokens\n",
    "  - Result: Approximately 14 lines of text\n",
    "- Test 2:\n",
    "  - Max length: 90 tokens\n",
    "  - Result: Response reduced to 2 lines\n",
    "\n",
    "### Repetition Parameter Availability\n",
    "- Not available in all models (e.g., absent in Cohere and Anthropic models)\n",
    "- Available in AI21 Labs model\n",
    "- Console interface shows options for presence penalty, count penalty, frequency penalty, and special token penalization\n",
    "\n",
    "## Key Points\n",
    "<span style=\"color:blue\">#keyPoints</span>\n",
    "- Length parameters crucial for controlling response size and API costs\n",
    "- Repetition parameters help in generating more diverse and less repetitive text\n",
    "- Parameter availability and ranges can vary significantly between different foundation models\n",
    "- Experimentation with these parameters can help in fine-tuning model outputs for specific use cases"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f12d0a25",
   "metadata": {},
   "source": [
    "# Amazon Bedrock Pricing\n",
    "\n",
    "## Table of Contents\n",
    "1. [Pricing Modes](#pricing-modes)\n",
    "2. [On-Demand Pricing](#on-demand-pricing)\n",
    "3. [Provisioned Throughput](#provisioned-throughput)\n",
    "4. [Pricing Example](#pricing-example)\n",
    "\n",
    "## Pricing Modes\n",
    "<span style=\"color:blue\">#pricingModes</span>\n",
    "- Two main modes:\n",
    "  1. On-demand mode\n",
    "  2. Provisioned throughput\n",
    "\n",
    "## On-Demand Pricing\n",
    "<span style=\"color:blue\">#onDemandPricing</span>\n",
    "\n",
    "### General Characteristics\n",
    "- Pay-as-you-go model\n",
    "- No time-based or unit-based commitments\n",
    "\n",
    "### Text Generation Models\n",
    "<span style=\"color:blue\">#textPricing</span>\n",
    "- Charged for both input and output tokens\n",
    "- Example (AI21 Labs Jurassic-2):\n",
    "  - $0.0125 per 1000 input tokens\n",
    "  - $0.0125 per 1000 output tokens\n",
    "- Token to word ratio: 1000 tokens ≈ 750 words\n",
    "\n",
    "### Image Generation Models\n",
    "<span style=\"color:blue\">#imagePricing</span>\n",
    "- Charged per image generated\n",
    "- Example (Stability AI Stable Diffusion):\n",
    "  - $0.018 per image (512x512 or smaller)\n",
    "  - $0.036 per image (larger than 512x512)\n",
    "\n",
    "### Embeddings\n",
    "<span style=\"color:blue\">#embeddingsPricing</span>\n",
    "- Charged for input tokens processed\n",
    "- Example (Cohere Command):\n",
    "  - $0.0015 per 1000 input tokens\n",
    "\n",
    "## Provisioned Throughput\n",
    "<span style=\"color:blue\">#provisionedThroughput</span>\n",
    "\n",
    "### Use Cases\n",
    "1. Large, consistent inference workloads needing guaranteed throughput\n",
    "2. Deployment of custom models\n",
    "\n",
    "### Characteristics\n",
    "- Requires time commitment (1-6 months)\n",
    "- Significantly more expensive than on-demand pricing\n",
    "\n",
    "### Pricing Examples\n",
    "- Anthropic:\n",
    "  - $40 per hour per model (1-month commitment)\n",
    "  - $22 per hour per model (6-month commitment)\n",
    "- Amazon Titan Text Light:\n",
    "  - Lower pricing compared to third-party models\n",
    "\n",
    "## Pricing Example\n",
    "<span style=\"color:blue\">#pricingExample</span>\n",
    "\n",
    "### Scenario\n",
    "- Using AI21 Jurassic-2 Mid model\n",
    "- Input: 10,000 tokens (≈7,500 words)\n",
    "- Output: 2,000 tokens (≈1,500 words)\n",
    "\n",
    "### Calculation\n",
    "- Input cost: (10,000 / 1000) * $0.0125 = $0.125\n",
    "- Output cost: (2,000 / 1000) * $0.0125 = $0.025\n",
    "- Total cost: $0.125 + $0.025 = $0.15\n",
    "\n",
    "## Key Points\n",
    "<span style=\"color:blue\">#keyPoints</span>\n",
    "- On-demand pricing is very cost-effective for most use cases\n",
    "- Provisioned throughput is significantly more expensive but offers guaranteed performance\n",
    "- Custom models require provisioned throughput\n",
    "- Actual costs can be very low for typical text processing tasks\n",
    "- Consider input and output token counts when estimating costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f542c34",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
